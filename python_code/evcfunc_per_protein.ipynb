{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate id lists for train, cross-train and test splits\n",
    "\n",
    "ids_dna = []\n",
    "ids_enzyme = []\n",
    "ids_more_data = []\n",
    "\n",
    "with open(\"data/ids_dna.txt\") as f:\n",
    "    for row in f:\n",
    "        ids_dna.append(row.strip())\n",
    "\n",
    "with open(\"data/ids_enzyme.txt\") as f:\n",
    "    for row in f:\n",
    "        ids_enzyme.append(row.strip())\n",
    "\n",
    "with open(\"data/ids_more_data.txt\") as f:\n",
    "    for row in f:\n",
    "        ids_more_data.append(row.strip())\n",
    "        \n",
    "random_indices_dna = random.sample(range(0,len(ids_dna)),5)\n",
    "random_indices_enzyme = random.sample(range(0,len(ids_enzyme)),36)\n",
    "\n",
    "test_dna = [ids_dna[x] for x in random_indices_dna]\n",
    "test_enzyme = [ids_enzyme[x] for x in random_indices_enzyme]\n",
    "\n",
    "ids_dna = [i for j, i in enumerate(ids_dna) if j not in random_indices_dna]\n",
    "ids_enzyme = [i for j, i in enumerate(ids_enzyme) if j not in random_indices_enzyme]\n",
    "\n",
    "ids = ids_dna + ids_enzyme\n",
    "random_indices = random.sample(range(0,len(ids)),len(ids))\n",
    "\n",
    "split1_indices = random_indices[0:74]\n",
    "split2_indices = random_indices[75:149]\n",
    "split3_indices = random_indices[150:224]\n",
    "split4_indices = random_indices[225:298]\n",
    "split5_indices = random_indices[299:372]\n",
    "\n",
    "test_ids = test_dna + test_enzyme\n",
    "split1_ids = [ids[x] for x in split1_indices]\n",
    "split2_ids = [ids[x] for x in split2_indices]\n",
    "split3_ids = [ids[x] for x in split3_indices]\n",
    "split4_ids = [ids[x] for x in split4_indices]\n",
    "split5_ids = [ids[x] for x in split5_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/test_set_ids.txt\",\"w\") as f:\n",
    "    f.write(\"\\n\".join(test_ids))\n",
    "\n",
    "with open(\"data/training_set_ids.txt\",\"w\") as f:\n",
    "    f.write(\"\\n\".join(split1_ids))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\".join(split2_ids))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\".join(split3_ids))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\".join(split4_ids))\n",
    "\n",
    "with open(\"data/cross_train_set_ids.txt\",\"w\") as f:\n",
    "    f.write(\"\\n\".join(split5_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# import data needed for the current model\n",
    "\n",
    "cols_to_remove = [40, 41]\n",
    "ranges = [[0,0], [1,2], [3,4], [5,5], [6,7], [8,9], [10,10], [11,12], [13,14], [15,15], [16,17], [18,19], \n",
    "          [20,20], [21,22], [23,24], [25,25], [26,27], [28,29], [30,30], [31,32], [33,34], [35,35], [36,37], [38,39]]\n",
    "\n",
    "model = \"mm3_avg_lr\"\n",
    "\n",
    "x_test, y_test, length_test = func.import_data(test_ids, cols_to_remove)\n",
    "x_split1, y_split1, length_split1 = func.import_data(split1_ids, cols_to_remove)\n",
    "x_split2, y_split2, length_split2 = func.import_data(split2_ids, cols_to_remove)\n",
    "x_split3, y_split3, length_split3 = func.import_data(split3_ids, cols_to_remove)\n",
    "x_split4, y_split4, length_split4 = func.import_data(split4_ids, cols_to_remove)\n",
    "x_split5, y_split5, length_split5 = func.import_data(split5_ids, cols_to_remove)\n",
    "x_more, y_more, length_more = func.import_data(ids_more_data, cols_to_remove)\n",
    "\n",
    "x_test = func.get_average_model(x_test,ranges)\n",
    "x_split1 = func.get_average_model(x_split1,ranges)\n",
    "x_split2 = func.get_average_model(x_split2,ranges)\n",
    "x_split3 = func.get_average_model(x_split3,ranges)\n",
    "x_split4 = func.get_average_model(x_split4,ranges)\n",
    "x_split5 = func.get_average_model(x_split5,ranges)\n",
    "x_more = func.get_average_model(x_more,ranges)\n",
    "print(len(x_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "# train neural network and analyse performance\n",
    "\n",
    "x_train = x_split1 + x_split2 + x_split3 + x_split4 #+ x_more\n",
    "y_train = y_split1 + y_split2 + y_split3 + y_split4 #+ y_more\n",
    "x_cross = x_split5\n",
    "y_cross = y_split5\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train, y_train = sm.fit_sample(x_train,y_train)\n",
    "\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(200,), alpha=0.0001, random_state=1,tol=0.0000001)\n",
    "classifier.fit(x_train,y_train)\n",
    "\n",
    "print(classifier.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Python\\Python3.6\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "proba = classifier.predict_proba(x_cross)\n",
    "\n",
    "cutoffs = range(0,10000,1)\n",
    "precision = []\n",
    "coverage = []\n",
    "\n",
    "for cut in cutoffs:\n",
    "    # print(cut)\n",
    "    float_cut = cut/10000\n",
    "    \n",
    "    prediction = []\n",
    "    for el in proba:\n",
    "        if el[1]>=float_cut:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    prec = metrics.precision_score(y_cross, prediction, average=None)[1]\n",
    "    cov = metrics.recall_score(y_cross, prediction, average=None)[1]\n",
    "    precision.append(prec)\n",
    "    coverage.append(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n0.0\n0.0\n0.9999\n"
     ]
    }
   ],
   "source": [
    "# plot figure\n",
    "\n",
    "print(classifier.classes_)\n",
    "print(prec)\n",
    "print(cov)\n",
    "print(float_cut)\n",
    "\n",
    "# print(precision)\n",
    "# print(coverage)\n",
    "\n",
    "new_coverage, new_precision = zip(*sorted(zip(coverage, precision)))\n",
    "\n",
    "# print(new_precision)\n",
    "# print(new_coverage)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.title(\"Precision-Coverage-Curve for \" + model)\n",
    "plt.xlabel(\"Coverage\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim(0.0, 1.0)\n",
    "lw = 2\n",
    "plt.plot(new_coverage, new_precision,color=\"navy\")\n",
    "plt.plot(0.33,0.2,'or',color=\"red\")\n",
    "# plt.plot(0.337,0.239,'or',color=\"green\")\n",
    "\n",
    "fig.savefig(\"D:/Dropbox/masterthesis/thesis/plots/machine_learning/prec-cov-curves/\"+model+\"_prec_cov_curve.png\")\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# calculate performance\n",
    "\n",
    "print(len(classifier.coefs_[0]))\n",
    "\n",
    "performances = func.bootstrapping(classifier, x_cross, y_cross)\n",
    "performances = np.array(performances)\n",
    "\n",
    "#print(performances)\n",
    "\n",
    "mean_performances = np.mean(performances,axis=0)\n",
    "sd_performances = np.std(performances,axis=0)\n",
    "sd_performances = sd_performances/sqrt(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/performance/performance_mean.txt\",\"a\") as f:\n",
    "    f.write(model)\n",
    "    for x in mean_performances:\n",
    "        f.write(\"\\t\"+str(x))\n",
    "    f.write(\"\\t\"+str(classifier.n_iter_)+\"\\t\"+str(len(classifier.coefs_[0]))+\"\\n\")\n",
    "\n",
    "with open(\"data/performance/performance_sd.txt\",\"a\") as f:\n",
    "    f.write(model)\n",
    "    for x in sd_performances:\n",
    "        f.write(\"\\t\"+str(x))\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "test = [1,2,3,4,5,6,7]\n",
    "print(test[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for overtraining and different hidden units\n",
    "\n",
    "\n",
    "# hidden_layers = ((10,), (50,), (100,), (200,), (300,), (500,))\n",
    "hidden_layers = ((1,), (700,))\n",
    "iterations = (20, 40, 60, 80, 100, 120, 140, 160, 300, 500)\n",
    "\n",
    "for layers in hidden_layers:\n",
    "    print(layers)\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for iter in iterations:\n",
    "        print(iter)\n",
    "        classifier = MLPClassifier(hidden_layer_sizes=layers,max_iter=iter,tol=-100)   \n",
    "        classifier.fit(x_train,y_train)\n",
    "        \n",
    "        train_score = classifier.score(x_train,y_train)\n",
    "        test_score = classifier.score(x_cross,y_cross)\n",
    "        \n",
    "        train_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        print(train_score)\n",
    "        print(test_score)\n",
    "        \n",
    "        print(classifier.n_iter_)\n",
    "\n",
    "    # plot figure\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    plt.title(\"Validation Curve for MM3 (5) \" + str(layers))\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0.6, 1.0)\n",
    "    lw = 2\n",
    "    plt.plot(iterations, train_scores, label=\"Training score\",\n",
    "             color=\"red\", lw=lw)\n",
    "    plt.plot(iterations, test_scores, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    fig.savefig(\"D:/Dropbox/masterthesis/thesis/plots/machine_learning/hidden_units/\"+model+\"_\" + str(layers) + \".png\")\n",
    "    plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}