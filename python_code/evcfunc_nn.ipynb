{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection, metrics, utils\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions\n",
    "\n",
    "def classifier_estimation(classifier, x_test, y_test):\n",
    "    print\n",
    "    print('Test set has ', len([i for i in y_test if i is 1]), 'positives and ', len([i for i in y_test if i is 0]), ' negatives')\n",
    "    print\n",
    "    print ('Best classifier score')\n",
    "    print\n",
    "    print(metrics.classification_report(y_test, classifier.predict(x_test), target_names=['non-binding', 'binding']))\n",
    "    \n",
    "    \n",
    "def calculate_performance(classifier, x_test, y_test):\n",
    "    \n",
    "    prec = metrics.precision_score(y_test,classifier.predict(x_test),average=None)\n",
    "    sensi = metrics.recall_score(y_test,classifier.predict(x_test),average=None)\n",
    "    f1 = metrics.f1_score(y_test,classifier.predict(x_test),average=None)\n",
    "    \n",
    "    performance = [round(prec[0],3),round(prec[1],3),round(sensi[0],3),round(sensi[1],3),round(f1[0],3),round(f1[1],3)]\n",
    "    return performance\n",
    "\n",
    "\n",
    "def bootstrapping(classifier, x_test, y_test):\n",
    "    size = int(round(len(x_test)/2))\n",
    "    performances = []\n",
    "\n",
    "    for i in range(0,999):\n",
    "        part_x,part_y = utils.resample(x_test,y_test,replace=False,n_samples=size)\n",
    "        tmp_performance = calculate_performance(classifier,part_x,part_y)\n",
    "        string_performance = \"\\t\".join([str(i) for i in tmp_performance])\n",
    "        performances.append(string_performance)\n",
    "       \n",
    "    return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general specifications\n",
    "\n",
    "path = \"data/\"\n",
    "model = \"minimal_model_sw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "positives_dna = []\n",
    "negatives_dna = []\n",
    "positives_enzyme = []\n",
    "negatives_enzyme = []\n",
    "\n",
    "with open(path+model+'_pdidb_positives.txt') as p_dna:\n",
    "    for row in csv.reader(p_dna,delimiter=\"\\t\"):\n",
    "        positives_dna.append(row)\n",
    "\n",
    "with open(path+model+'_pdidb_negatives.txt') as n_dna:\n",
    "    for row in csv.reader(n_dna,delimiter=\"\\t\"):\n",
    "        negatives_dna.append(row)\n",
    "       \n",
    "with open(path+model+'_enzyme_positives.txt') as p_enzyme:\n",
    "    for row in csv.reader(p_enzyme,delimiter=\"\\t\"):\n",
    "        positives_enzyme.append(row)\n",
    "        \n",
    "with open(path+model+'_enzyme_negatives.txt') as n_enzyme:\n",
    "    for row in csv.reader(n_enzyme,delimiter=\"\\t\"):\n",
    "        negatives_enzyme.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process data\n",
    "\n",
    "# remove elements representing distances //TODO\n",
    "\n",
    "\n",
    "tmp_dna = positives_dna + negatives_dna\n",
    "tmp_enzyme = positives_enzyme + negatives_enzyme\n",
    "\n",
    "labels_dna = [1]*len(positives_dna)+[0]*len(negatives_dna)\n",
    "labels_enzyme = [1]*len(positives_enzyme)+[0]*len(negatives_enzyme)\n",
    "\n",
    "dna = []\n",
    "enzyme = []\n",
    "\n",
    "for j in tmp_dna:\n",
    "    new_j = [float(i) for i in j]\n",
    "    dna.append(new_j)\n",
    "    \n",
    "for j in tmp_enzyme:\n",
    "    new_j = [float(i) for i in j]\n",
    "    enzyme.append(new_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test datasets\n",
    "\n",
    "dna_x_train,dna_x_test,dna_y_train,dna_y_test = model_selection.train_test_split(dna, labels_dna, test_size=0.2, random_state=6)\n",
    "enzyme_x_train,enzyme_x_test,enzyme_y_train,enzyme_y_test = model_selection.train_test_split(enzyme,labels_enzyme,test_size=0.2,random_state=6)\n",
    "\n",
    "x_train = dna_x_train + enzyme_x_train\n",
    "y_train = dna_y_train + enzyme_y_train\n",
    "x_test = dna_x_test + enzyme_x_test\n",
    "y_test = dna_y_test + enzyme_y_test\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train, y_train = sm.fit_sample(x_train,y_train)\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the neural network\n",
    "\n",
    "parameters = {'alpha': [0.0001], 'random_state': [1]}\n",
    "grid = model_selection.GridSearchCV(MLPClassifier(), parameters, cv=kf)\n",
    "grid.fit(x_train,y_train)\n",
    "classifier = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(100,), learning_rate='constant',\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# get information about the best classifier\n",
    "\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 12298, 1: 3335}\nTest set has  1335 positives and  11615  negatives\nBest classifier score\n             precision    recall  f1-score   support\n\nnon-binding       0.92      0.82      0.86     11615\n    binding       0.19      0.38      0.26      1335\n\navg / total       0.84      0.77      0.80     12950\n\nTest set has  363 positives and  2320  negatives\nBest classifier score\n             precision    recall  f1-score   support\n\nnon-binding       0.90      0.78      0.83      2320\n    binding       0.24      0.46      0.32       363\n\navg / total       0.81      0.73      0.77      2683\n\nTest set has  1698 positives and  13935  negatives\nBest classifier score\n             precision    recall  f1-score   support\n\nnon-binding       0.92      0.81      0.86     13935\n    binding       0.20      0.40      0.27      1698\n\navg / total       0.84      0.76      0.80     15633\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91689705643194019, 0.20269865067466267, 0.80918550412630064, 0.39811542991755006, 0.85968055502611207, 0.26862706139479436]\nTraining set score: 0.800120\nTest set score: 0.764537\n3\n128\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "# prediction = classifier.predict(enzyme_x_test)\n",
    "# prediction = classifier.predict(x_test)\n",
    "# unique, counts = np.unique(prediction, return_counts=True)\n",
    "# print(dict(zip(unique, counts)))\n",
    "\n",
    "classifier_estimation(classifier,enzyme_x_test,enzyme_y_test)\n",
    "classifier_estimation(classifier,dna_x_test, dna_y_test)\n",
    "classifier_estimation(classifier,x_test,y_test)\n",
    "\n",
    "print(\"Training set score: %f\" % classifier.score(x_train, y_train))\n",
    "print(\"Test set score: %f\" % classifier.score(x_test, y_test))\n",
    "print(classifier.n_layers_)\n",
    "print(classifier.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapping to get performance distribution\n",
    "\n",
    "performances = bootstrapping(classifier,x_test,y_test)\n",
    "performances_dna = bootstrapping(classifier,dna_x_test,dna_y_test)\n",
    "performances_enzyme = bootstrapping(classifier,enzyme_x_test,enzyme_y_test)\n",
    "    \n",
    "with open(path+'performance_'+model+'.txt',\"w\") as o:\n",
    "    o.write(\"\\n\".join(performances))\n",
    "    \n",
    "with open(path+'performance_'+model+'_pdidb.txt',\"w\") as o:\n",
    "    o.write(\"\\n\".join(performances_dna))\n",
    "    \n",
    "with open(path+'performance_'+model+'_enzyme.txt',\"w\") as o:\n",
    "    o.write(\"\\n\".join(performances_enzyme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random data\n",
    "\n",
    "positives_dna_rnd = []\n",
    "negatives_dna_rnd = []\n",
    "positives_enzyme_rnd = []\n",
    "negatives_enzyme_rnd = []\n",
    "\n",
    "with open('data/rnd_more_minimal_model_pdidb_positives.txt') as p_dna:\n",
    "    for row in csv.reader(p_dna,delimiter=\"\\t\"):\n",
    "        positives_dna_rnd.append(row)\n",
    "\n",
    "with open('data/rnd_more_minimal_model_pdidb_negatives.txt') as n_dna:\n",
    "    for row in csv.reader(n_dna,delimiter=\"\\t\"):\n",
    "        negatives_dna_rnd.append(row)\n",
    "       \n",
    "with open('data/rnd_more_minimal_model_enzyme_positives.txt') as p_enzyme:\n",
    "    for row in csv.reader(p_enzyme,delimiter=\"\\t\"):\n",
    "        positives_enzyme_rnd.append(row)\n",
    "        \n",
    "with open('data/rnd_more_minimal_model_enzyme_negatives.txt') as n_enzyme:\n",
    "    for row in csv.reader(n_enzyme,delimiter=\"\\t\"):\n",
    "        negatives_enzyme_rnd.append(row)\n",
    "        \n",
    "#positives_dna_rnd = [x[1:len(positives_dna_rnd[0])-1] for x in positives_dna_rnd]\n",
    "#negatives_dna_rnd = [x[1:len(negatives_dna_rnd[0])-1] for x in negatives_dna_rnd]\n",
    "#positives_enzyme_rnd = [x[1:len(positives_enzyme_rnd[0])-1] for x in positives_enzyme_rnd]\n",
    "#negatives_enzyme_rnd = [x[1:len(negatives_enzyme_rnd[0])-1] for x in negatives_enzyme_rnd]\n",
    "        \n",
    "tmp_dna_rnd = positives_dna_rnd + negatives_dna_rnd\n",
    "tmp_enzyme_rnd = positives_enzyme_rnd + negatives_enzyme_rnd\n",
    "\n",
    "labels_dna_rnd = [1]*len(positives_dna_rnd)+[0]*len(negatives_dna_rnd)\n",
    "labels_enzyme_rnd = [1]*len(positives_enzyme_rnd)+[0]*len(negatives_enzyme_rnd)\n",
    "\n",
    "dna_rnd = []\n",
    "enzyme_rnd = []\n",
    "\n",
    "for j in tmp_dna_rnd:\n",
    "    new_j = [float(i) for i in j]\n",
    "    dna_rnd.append(new_j)\n",
    "\n",
    "for j in tmp_enzyme_rnd:\n",
    "    new_j = [float(i) for i in j]\n",
    "    enzyme_rnd.append(new_j)\n",
    "\n",
    "data_rnd = dna_rnd + enzyme_rnd\n",
    "labels_rnd = labels_dna_rnd + labels_enzyme_rnd\n",
    "\n",
    "dna_x_train_rnd,dna_x_test_rnd,dna_y_train_rnd,dna_y_test_rnd = model_selection.train_test_split(dna_rnd,labels_dna_rnd,test_size=0.2,random_state=6)\n",
    "enzyme_x_train_rnd,enzyme_x_test_rnd,enzyme_y_train_rnd,enzyme_y_test_rnd = model_selection.train_test_split(enzyme_rnd,labels_enzyme_rnd,test_size=0.2,random_state=6)\n",
    "\n",
    "x_test_rnd = dna_x_test_rnd + enzyme_x_test_rnd\n",
    "y_test_rnd = dna_y_test_rnd + enzyme_y_test_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 44187, 1: 33978}\nTest set has  6581 positives and  58169  negatives\nBest classifier score\n             precision    recall  f1-score   support\n\nnon-binding       0.90      0.57      0.70     58169\n    binding       0.11      0.46      0.17      6581\n\navg / total       0.82      0.56      0.64     64750\n\nTest set has  1678 positives and  11737  negatives\nBest classifier score\n             precision    recall  f1-score   support\n\nnon-binding       0.88      0.57      0.69     11737\n    binding       0.14      0.47      0.21      1678\n\navg / total       0.79      0.56      0.63     13415\n\nTest set has  8259 positives and  69906  negatives\nBest classifier score\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n\nnon-binding       0.90      0.57      0.70     69906\n    binding       0.11      0.46      0.18      8259\n\navg / total       0.82      0.56      0.64     78165\n\nTest set score: 0.556643\n"
     ]
    }
   ],
   "source": [
    "#comparison to random\n",
    "\n",
    "#prediction = classifier.predict(enzyme_x_test)\n",
    "prediction = classifier.predict(data_rnd)\n",
    "unique, counts = np.unique(prediction, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "classifier_estimation(classifier,enzyme_rnd,labels_enzyme_rnd)\n",
    "classifier_estimation(classifier,dna_rnd,labels_dna_rnd)\n",
    "classifier_estimation(classifier,data_rnd,labels_rnd)\n",
    "\n",
    "print(\"Test set score: %f\" % classifier.score(data_rnd,labels_rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}